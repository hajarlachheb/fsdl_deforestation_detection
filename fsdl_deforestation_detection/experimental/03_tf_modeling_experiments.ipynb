{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0456bd785d8e5f824a083d6101f0398d6be9e4f6de2819b539c11db9841cfcc7d",
   "display_name": "Python 3.7.10 64-bit ('fsdl-deforestation-detection-TMUxwj1S-py3.7': poetry)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TensorFlow modeling experiments\n",
    "---\n",
    "\n",
    "Notebook for initial experiments on modeling deforestation through TensorFlow and the [Planet: Understanding the Amazon from Space](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/) dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow_addons.metrics import FBetaScore\n",
    "from tensorflow.keras import losses, optimizers, metrics\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "from tqdm.keras import TqdmCallback\n",
    "from ipywidgets import interact\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../data/')\n",
    "sys.path.append('../modeling/')\n",
    "import data_utils\n",
    "from models import ResNet, data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'resnet50'\n",
    "task = 'orig_labels'\n",
    "pretrain_dataset = 'bigearthnet'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def choose_model_and_task(chosen_model_type=['resnet50', 'pretrained_resnet50'], chosen_task=['orig_labels', 'deforestation']):\n",
    "    global model_type\n",
    "    global task\n",
    "    global pretrain_dataset\n",
    "    model_type, task = chosen_model_type, chosen_task\n",
    "    if chosen_model_type == 'pretrained_resnet50':\n",
    "        pretrain_dataset = 'bigearthnet'\n",
    "        # pretrain_dataset = 'imagenet'\n",
    "    else:\n",
    "        pretrain_dataset = None"
   ]
  },
  {
   "source": [
    "## Load the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Create a dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(data_utils.DATA_PATH + data_utils.LABELS_PATH)\n",
    "labels_df = data_utils.encode_tags(labels_df, drop_tags_col=True)\n",
    "if task == 'deforestation':\n",
    "    labels_df = data_utils.add_deforestation_label(labels_df)\n",
    "    labels_df = labels_df[['image_name', 'deforestation']]\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dataframe so that the generator has no required arguments\n",
    "def data_gen():\n",
    "    for i in data_utils.get_amazon_sample(labels_df):\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'deforestation':\n",
    "    labels_shape = 1\n",
    "else:\n",
    "    labels_shape = len(data_utils.TAGS)\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_gen, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=([256, 256, 3]), dtype=tf.float16),\n",
    "        tf.TensorSpec(shape=(labels_shape), dtype=tf.uint8)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "source": [
    "Alternative dataset creation, following typical TensorFlow image loading approaches, but which is slower:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names = [f\"{data_utils.DATA_PATH}{data_utils.IMG_PATH}{image_name}.jpg\" for image_name in labels_df.image_name.tolist()]\n",
    "# if task == 'deforestation':\n",
    "#     labels = labels_df['deforestation'].tolist()\n",
    "# else:\n",
    "#     labels = labels_df[data_utils.TAGS].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices((file_names, labels)).map(data_utils.decode_img, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(dataset))"
   ]
  },
  {
   "source": [
    "### Split into train, validation and test sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(labels_df)\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = dataset.take(int(0.9 * n_samples)), dataset.skip(int(0.9 * n_samples))\n",
    "train_set, val_set = train_set.skip(int(0.1 * n_samples)), train_set.take(int(0.1 * n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.cache().shuffle(buffer_size=1000).batch(batch_size).prefetch(AUTOTUNE)\n",
    "val_set = val_set.cache().shuffle(buffer_size=1000).batch(batch_size).prefetch(AUTOTUNE)\n",
    "test_set = test_set.cache().shuffle(buffer_size=1000).batch(batch_size).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch = train_set.take(1)"
   ]
  },
  {
   "source": [
    "## Train models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Set the modeling configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(\n",
    "    pretrain_dataset=pretrain_dataset,\n",
    "    pooling='max',\n",
    "    task=task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build(input_shape=(None, 256, 256, 3))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrain_dataset is not None:\n",
    "    model.core.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.003\n",
    "opt = optimizers.Adam(learning_rate=lr)\n",
    "# if task == 'orig_labels':\n",
    "#     loss = losses.CategoricalCrossentropy()#from_logits=True)\n",
    "# else:\n",
    "#     loss = losses.BinaryCrossentropy()#from_logits=True)\n",
    "loss = 'binary_crossentropy'\n",
    "model_metrics = [\n",
    "    'accuracy', \n",
    "    FBetaScore(num_classes=model.n_outputs, average='macro', beta=2.0)\n",
    "]"
   ]
  },
  {
   "source": [
    "### Test a model\n",
    "\n",
    "Overfit a model on a batch of a classification task, so as to confirm that it works."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Train on a single batch:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=loss, metrics=model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(single_batch, epochs=100, verbose=0, callbacks=[TqdmCallback()])"
   ]
  },
  {
   "source": [
    "Manually test each step of the model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(single_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = batch_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == 'orig_labels':\n",
    "    y_ohe = tf.cast(y_pred > (1 / len(data_utils.TAGS)), tf.uint8)\n",
    "else:\n",
    "    y_ohe = tf.cast(y_pred > 0.5, tf.uint8)\n",
    "y_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ohe == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_proc = model.preprocess_input(x)\n",
    "x_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(x_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(x_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(x_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_aug = data_augmentation(x_proc)\n",
    "x_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_core = model.core(x_aug)\n",
    "x_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(x_core, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.classifier(x_core)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x, y, epochs=100, verbose=0, callbacks=[TqdmCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}